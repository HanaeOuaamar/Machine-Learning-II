{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be670849-1779-43f6-b825-e4743b241bd3",
   "metadata": {},
   "source": [
    " <div style=\"border: 2px solid black; padding: 10px; background-color: #f7f7f7; text-align: center;\">\r\n",
    "    <h1 style=\"color:Navy;; text-decoration: underline;\">TP: Machine Learning II1</h1>\r\n",
    "</div>\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6580adfb-9271-4e52-92b7-5440129cb70e",
   "metadata": {},
   "source": [
    "### <u> *Partie 1:Présentation des bibliothèques clés*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b0857e2-a087-46c7-acf4-970fc9a214f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.01825906, -0.01260786,  0.04556217, -0.03128231], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création de l’environnement\n",
    "import gymnasium as gym\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb81b66e-8bbb-4b61-a233-7afd23e290d0",
   "metadata": {},
   "source": [
    "### <u> * Partie 2 : Exercices pratiques avec OpenAI Gym*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16337cf-5270-4012-bf86-ba402288dd29",
   "metadata": {},
   "source": [
    "####   Exercie1 : Découverte et exploration d’un environnement Gym\n",
    "##### Objectif: Comprendre la structure d'un environnement Gym en explorant des propriétés et ses actions possibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88194256-4d48-466c-a107-7b3fc75360ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espace d'actions : Discrete(2)\n",
      "Espace d'observations : Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n",
      "Action : 1, Observation : [-0.01851121  0.18183209  0.04493653 -0.30924892], Reward : 1.0\n",
      "Action : 1, Observation : [-0.01487457  0.37628594  0.03875155 -0.58742833], Reward : 1.0\n",
      "Action : 0, Observation : [-0.00734885  0.18064332  0.02700298 -0.28279462], Reward : 1.0\n",
      "Action : 1, Observation : [-0.00373599  0.3753699   0.02134709 -0.5668401 ], Reward : 1.0\n",
      "Action : 1, Observation : [ 0.00377141  0.570186    0.01001029 -0.8527221 ], Reward : 1.0\n",
      "Action : 1, Observation : [ 0.01517513  0.7651701  -0.00704416 -1.1422406 ], Reward : 1.0\n",
      "Action : 1, Observation : [ 0.03047853  0.96038336 -0.02988897 -1.4371243 ], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.0496862   0.76564234 -0.05863145 -1.1539292 ], Reward : 1.0\n",
      "Action : 1, Observation : [ 0.06499905  0.9614779  -0.08171004 -1.4644055 ], Reward : 1.0\n",
      "Action : 1, Observation : [ 0.08422861  1.1575001  -0.11099815 -1.781454  ], Reward : 1.0\n",
      "Action : 1, Observation : [ 0.10737861  1.3536818  -0.14662723 -2.106482  ], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.13445225  1.1603023  -0.18875687 -1.8624794 ], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.1576583   0.96768475 -0.22600646 -1.6338505 ], Reward : 1.0\n",
      "Action : 0, Observation : [-0.0312053  -0.20163105  0.0385724   0.29273334], Reward : 1.0\n",
      "Action : 0, Observation : [-0.03523792 -0.39728114  0.04442707  0.59732765], Reward : 1.0\n",
      "Action : 1, Observation : [-0.04318354 -0.2028081   0.05637362  0.31896317], Reward : 1.0\n",
      "Action : 1, Observation : [-0.04723971 -0.00853246  0.06275289  0.04457771], Reward : 1.0\n",
      "Action : 0, Observation : [-0.04741035 -0.2044955   0.06364444  0.35638094], Reward : 1.0\n",
      "Action : 0, Observation : [-0.05150026 -0.40046185  0.07077206  0.6684342 ], Reward : 1.0\n",
      "Action : 1, Observation : [-0.0595095  -0.20639168  0.08414075  0.39884725], Reward : 1.0\n",
      "Action : 1, Observation : [-0.06363734 -0.01255787  0.09211769  0.13383335], Reward : 1.0\n",
      "Action : 1, Observation : [-0.0638885   0.18113212  0.09479436 -0.12842551], Reward : 1.0\n",
      "Action : 1, Observation : [-0.06026585  0.3747773   0.09222585 -0.38976136], Reward : 1.0\n",
      "Action : 1, Observation : [-0.05277031  0.5684775   0.08443062 -0.65200096], Reward : 1.0\n",
      "Action : 0, Observation : [-0.04140076  0.3722875   0.0713906  -0.3339711 ], Reward : 1.0\n",
      "Action : 0, Observation : [-0.033955    0.17622595  0.06471118 -0.01965686], Reward : 1.0\n",
      "Action : 1, Observation : [-0.03043049  0.37036306  0.06431804 -0.2912412 ], Reward : 1.0\n",
      "Action : 1, Observation : [-0.02302323  0.5645118   0.05849322 -0.56296563], Reward : 1.0\n",
      "Action : 0, Observation : [-0.01173299  0.36861992  0.04723391 -0.2524432 ], Reward : 1.0\n",
      "Action : 0, Observation : [-0.00436059  0.17285644  0.04218504  0.05475612], Reward : 1.0\n",
      "Action : 0, Observation : [-0.00090346 -0.0228442   0.04328016  0.36044464], Reward : 1.0\n",
      "Action : 1, Observation : [-0.00136035  0.17163667  0.05048906  0.08171692], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.00207239 -0.02417132  0.05212339  0.3898921 ], Reward : 1.0\n",
      "Action : 1, Observation : [0.00158896 0.17017359 0.05992123 0.11408799], Reward : 1.0\n",
      "Action : 1, Observation : [ 0.00499243  0.36438802  0.062203   -0.15910453], Reward : 1.0\n",
      "Action : 0, Observation : [0.01228019 0.16843323 0.05902091 0.1525351 ], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.01564886 -0.02748198  0.06207161  0.4632383 ], Reward : 1.0\n",
      "Action : 1, Observation : [0.01509922 0.16671038 0.07133637 0.19074807], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.01843343 -0.02935577  0.07515133  0.5050544 ], Reward : 1.0\n",
      "Action : 1, Observation : [0.01784631 0.16463113 0.08525242 0.23696905], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.02113893 -0.03159878  0.0899918   0.5552788 ], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.02050696 -0.22786137  0.10109738  0.87490326], Reward : 1.0\n",
      "Action : 1, Observation : [ 0.01594973 -0.03424838  0.11859544  0.6156387 ], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.01526476 -0.23081017  0.13090822  0.9431957 ], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.01064856 -0.42742974  0.14977214  1.2739787 ], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.00209996 -0.62411094  0.1752517   1.6095665 ], Reward : 1.0\n",
      "Action : 0, Observation : [-0.01038226 -0.8208169   0.20744304  1.9513665 ], Reward : 1.0\n",
      "Action : 0, Observation : [-0.02679859 -1.0174538   0.24647036  2.30055   ], Reward : 1.0\n",
      "Action : 1, Observation : [-0.02792736  0.1884744   0.03756504 -0.32331708], Reward : 1.0\n",
      "Action : 1, Observation : [-0.02415787  0.38304186  0.0310987  -0.6039209 ], Reward : 1.0\n",
      "Action : 0, Observation : [-0.01649703  0.18749909  0.01902028 -0.30160698], Reward : 1.0\n",
      "Action : 1, Observation : [-0.01274705  0.38234487  0.01298814 -0.58823115], Reward : 1.0\n",
      "Action : 0, Observation : [-0.00510016  0.18704346  0.00122352 -0.29148537], Reward : 1.0\n",
      "Action : 1, Observation : [-0.00135929  0.38214794 -0.00460619 -0.58378214], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.00628367  0.18709083 -0.01628183 -0.29255378], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.01002549 -0.00779524 -0.02213291 -0.00505008], Reward : 1.0\n",
      "Action : 1, Observation : [ 0.00986958  0.18763702 -0.02223391 -0.30463323], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.01362232 -0.00716114 -0.02832657 -0.01904443], Reward : 1.0\n",
      "Action : 1, Observation : [ 0.0134791   0.18835536 -0.02870746 -0.32052842], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.01724621 -0.00634625 -0.03511803 -0.03703517], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.01711928 -0.20094746 -0.03585874  0.24436408], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.01310034 -0.39553937 -0.03097145  0.5255241 ], Reward : 1.0\n",
      "Action : 1, Observation : [ 0.00518955 -0.1999956  -0.02046097  0.22324495], Reward : 1.0\n",
      "Action : 0, Observation : [ 0.00118964 -0.39481923 -0.01599607  0.5094041 ], Reward : 1.0\n",
      "Action : 1, Observation : [-0.00670675 -0.19947562 -0.00580799  0.21172354], Reward : 1.0\n",
      "Action : 1, Observation : [-0.01069626 -0.0042711  -0.00157352 -0.08278583], Reward : 1.0\n",
      "Action : 0, Observation : [-0.01078168 -0.19937046 -0.00322924  0.20940024], Reward : 1.0\n",
      "Action : 1, Observation : [-0.01476909 -0.00420249  0.00095877 -0.0842996 ], Reward : 1.0\n",
      "Action : 0, Observation : [-0.01485314 -0.19933817 -0.00072722  0.20868567], Reward : 1.0\n",
      "Action : 1, Observation : [-0.01883991 -0.00420583  0.00344649 -0.08422657], Reward : 1.0\n",
      "Action : 1, Observation : [-0.01892402  0.19086656  0.00176196 -0.37582013], Reward : 1.0\n",
      "Action : 0, Observation : [-0.01510669 -0.00428038 -0.00575444 -0.08258218], Reward : 1.0\n",
      "Action : 1, Observation : [-0.0151923   0.19092359 -0.00740609 -0.37707508], Reward : 1.0\n",
      "Action : 0, Observation : [-0.01137383 -0.0040924  -0.01494759 -0.08673649], Reward : 1.0\n",
      "Action : 0, Observation : [-0.01145567 -0.19899693 -0.01668232  0.20119323], Reward : 1.0\n",
      "Action : 1, Observation : [-0.01543561 -0.00364042 -0.01265845 -0.09670515], Reward : 1.0\n",
      "Action : 1, Observation : [-0.01550842  0.19166064 -0.01459256 -0.39335477], Reward : 1.0\n",
      "Action : 0, Observation : [-0.01167521 -0.00325122 -0.02245965 -0.10530815], Reward : 1.0\n",
      "Action : 0, Observation : [-0.01174023 -0.19804423 -0.02456582  0.18020509], Reward : 1.0\n",
      "Action : 0, Observation : [-0.01570112 -0.3928062  -0.02096171  0.46503827], Reward : 1.0\n",
      "Action : 1, Observation : [-0.02355724 -0.19739442 -0.01166095  0.1658227 ], Reward : 1.0\n",
      "Action : 1, Observation : [-0.02750513 -0.00210749 -0.0083445  -0.13051601], Reward : 1.0\n",
      "Action : 1, Observation : [-0.02754728  0.193133   -0.01095481 -0.42581978], Reward : 1.0\n",
      "Action : 0, Observation : [-0.02368462 -0.00183209 -0.01947121 -0.13661037], Reward : 1.0\n",
      "Action : 1, Observation : [-0.02372126  0.19356325 -0.02220342 -0.43537202], Reward : 1.0\n",
      "Action : 0, Observation : [-0.01985    -0.00123745 -0.03091086 -0.14977024], Reward : 1.0\n",
      "Action : 1, Observation : [-0.01987475  0.19431318 -0.03390626 -0.4520424 ], Reward : 1.0\n",
      "Action : 0, Observation : [-0.01598848 -0.00031326 -0.04294711 -0.17023706], Reward : 1.0\n",
      "Action : 0, Observation : [-0.01599475 -0.19479503 -0.04635185  0.10859402], Reward : 1.0\n",
      "Action : 0, Observation : [-0.01989065 -0.38922316 -0.04417997  0.3863004 ], Reward : 1.0\n",
      "Action : 1, Observation : [-0.02767511 -0.1935028  -0.03645397  0.08002166], Reward : 1.0\n",
      "Action : 0, Observation : [-0.03154517 -0.38808373 -0.03485353  0.36098403], Reward : 1.0\n",
      "Action : 0, Observation : [-0.03930684 -0.5826934  -0.02763385  0.6424764 ], Reward : 1.0\n",
      "Action : 0, Observation : [-0.05096071 -0.77741945 -0.01478432  0.9263307 ], Reward : 1.0\n",
      "Action : 1, Observation : [-0.0665091  -0.582101    0.00374229  0.6290386 ], Reward : 1.0\n",
      "Action : 1, Observation : [-0.07815112 -0.3870315   0.01632306  0.33753657], Reward : 1.0\n",
      "Action : 0, Observation : [-0.08589175 -0.58238184  0.02307379  0.63532186], Reward : 1.0\n",
      "Action : 1, Observation : [-0.09753939 -0.38758922  0.03578023  0.34999377], Reward : 1.0\n",
      "Action : 0, Observation : [-0.10529117 -0.5832013   0.04278011  0.6537412 ], Reward : 1.0\n",
      "Action : 1, Observation : [-0.1169552  -0.3887003   0.05585493  0.3748302 ], Reward : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Affichage de l’espace d’actions et d’observations\n",
    "print(f\"Espace d'actions : {env.action_space}\")\n",
    "print(f\"Espace d'observations : {env.observation_space}\")\n",
    "# Boucle de simulation avec actions aléatoires\n",
    "for _ in range(100):\n",
    "    action = env.action_space.sample()  # Action aléatoire\n",
    "    observation, reward, done, truncated, info = env.step(action)\n",
    "    print(f\"Action : {action}, Observation : {observation}, Reward : {reward}\")\n",
    "    if done:\n",
    "        env.reset()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ecb9eb-131e-4efa-b3e1-465804183e9d",
   "metadata": {},
   "source": [
    "####   Exercie2 : Manipulation des observations et récompenses\n",
    "##### Objectif : Comprendre comment récupérer les observations et les récompenses lors de l’interaction avec l’environnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e530888-8be5-404f-9d6f-c59a07682969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation : [-0.02818875  0.22191362  0.02243161 -0.2709426 ], Reward : 1.0, Done : False\n",
      "Observation : [-0.02375048  0.4167084   0.01701276 -0.55646694], Reward : 1.0, Done : False\n",
      "Observation : [-0.01541631  0.2213518   0.00588342 -0.25847292], Reward : 1.0, Done : False\n",
      "Observation : [-0.01098928  0.02614636  0.00071396  0.03605989], Reward : 1.0, Done : False\n",
      "Observation : [-0.01046635 -0.16898583  0.00143516  0.328968  ], Reward : 1.0, Done : False\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "observation, info = env.reset()\n",
    "\n",
    "# Essais multiples pour observer la variation des résultats\n",
    "for _ in range(5):\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, truncated, info = env.step(action)\n",
    "    print(f\"Observation : {observation}, Reward : {reward}, Done : {done}\")\n",
    "    if done or truncated:\n",
    "        observation, info = env.reset()\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc9df76-9108-42a6-a10c-59c89ace29a1",
   "metadata": {},
   "source": [
    "#### Exercice 3 : Contrôle manuel de l'agent\n",
    "##### Objectif : Permettre à l'utilisateur de contrôler manuellement l'agent afin de mieux comprendre l'effet des actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e74c1-9003-4039-83bb-d545c246685f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrez une action (0 ou 1) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation : [-0.02488356 -0.2373431   0.04067374  0.31306913], Reward : 1.0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrez une action (0 ou 1) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation : [-0.02963042 -0.43302017  0.04693512  0.61829674], Reward : 1.0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Entrez une action (0 ou 1) :  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation : [-0.03829083 -0.6287652   0.05930106  0.9253848 ], Reward : 1.0\n"
     ]
    }
   ],
   "source": [
    " import gymnasium as gym\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "observation, info = env.reset()\n",
    "done = False\n",
    "episode_length = 0\n",
    "\n",
    "while not done:\n",
    "    action = int(input(\"Entrez une action (0 ou 1) : \"))\n",
    "    observation, reward, done, truncated, info = env.step(action)\n",
    "    print(f\"Observation : {observation}, Reward : {reward}\")\n",
    "    episode_length += 1\n",
    "    if done or truncated:\n",
    "        break\n",
    "\n",
    "print(f\"Durée totale de l’épisode : {episode_length} étapes\")\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a9053-901e-4eea-9828-73c77a76658c",
   "metadata": {},
   "source": [
    "#### Exercice 4\n",
    "##### Objectif : Évaluation des performances d'une politique aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae72cc8a-98f0-4dbb-9859-06c3d3e892ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Épisode 1 : 12 étapes\n",
      "Épisode 2 : 69 étapes\n",
      "Épisode 3 : 11 étapes\n",
      "Épisode 4 : 25 étapes\n",
      "Épisode 5 : 21 étapes\n",
      "Épisode 6 : 13 étapes\n",
      "Épisode 7 : 34 étapes\n",
      "Épisode 8 : 9 étapes\n",
      "Épisode 9 : 11 étapes\n",
      "Épisode 10 : 25 étapes\n",
      "\n",
      "Durée moyenne sur 10 épisodes : 23.0 étapes\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "num_episodes = 10\n",
    "durations = []\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    observation, info = env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, truncated, info = env.step(action)\n",
    "        steps += 1\n",
    "        if done or truncated:\n",
    "            break\n",
    "    \n",
    "    durations.append(steps)\n",
    "    print(f\"Épisode {episode + 1} : {steps} étapes\")\n",
    "\n",
    "env.close()\n",
    "\n",
    "# Calcul de la moyenne\n",
    "average_duration = sum(durations) / num_episodes\n",
    "print(f\"\\nDurée moyenne sur {num_episodes} épisodes : {average_duration} étapes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
